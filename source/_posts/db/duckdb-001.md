---
title: 第一章 DuckDB 概述
date: 2025-05-21 11:03:53
tags: 
cover: cover.png
categories:
  - 计算机
  - 数据库
---
## 1.1 DuckDB 介绍

DuckDB 是一款功能强大、易于使用且性能卓越的分析型数据库，特别适合需要快速、轻量级、嵌入式数据分析的场景。它在处理本地文件和远程云存储上的列式数据方面表现出色，是现代数据工具链中一个日益重要的组成部分。

### 1.1.1 DuckDB 是什么？

DuckDB 是一个**高性能、嵌入式、分析型数据库管理系统 (DBMS)**。它被设计用来在您的应用程序内部直接运行，无需单独的服务器进程，类似于分析领域的 SQLite。

### 1.1.2 DuckDB 的核心特点和优势

1. **嵌入式 (Embedded)：**
    - **无需独立服务器：** DuckDB 不像传统的数据库（如 PostgreSQL, MySQL）那样需要一个独立的数据库服务器进程。它以库的形式集成到您的应用程序中（例如 Python、R、Java、Node.js 等），直接在应用程序的内存和文件系统中运行；
    - **零配置、易于部署：** 这使得它非常轻量级，易于分发和部署，几乎是零配置即可开始使用；
        
2. **分析型数据库 (Analytical Database / OLAP)：**
    - **专为 OLAP 工作负载优化：** 与事务型数据库（OLTP）不同，DuckDB 专门为在线分析处理（OLAP）工作负载而设计。它擅长处理复杂的分析查询，如聚合（SUM, AVG）、分组（GROUP BY）、H）、排序（ORDER BY）和连接（JOIN）大量数据；
    - **列式存储 (Columnar Storage)：** DuckDB 的内部数据存储是列式的。这意味着它将同一列的数据存储在一起；
        - **优势：** 这极大地提高了分析查询的效率，因为查询通常只涉及少数几列，DuckDB 无需读取不相关的列数据。它支持高效的**列裁剪 (Column Pruning)** 和**谓词下推 (Predicate Pushdown)**；
            
3. **高性能 (High Performance)：**
    - **向量化执行引擎：** DuckDB 采用向量化（vectorized）执行引擎，能够一次处理多行数据（批处理），极大地提升了查询速度；
    - **多核优化：** 充分利用现代 CPU 的多核优势进行并行计算；
    - **缓存友好：** 优化了数据访问模式以更好地利用 CPU 缓存；
        
4. **SQL 支持 (SQL Support)：**
    - DuckDB 支持标准的 SQL 语言，包括高级分析功能，如窗口函数（Window Functions）、通用表表达式（CTE）等；
        
5. **直接文件读取 (Direct File Reading)：**
    - 这是 DuckDB 的一个突出特性。它能够**直接从各种文件格式和远程存储中读取数据**，而无需预先导入到数据库中；
        - **支持格式：** Parquet, CSV, JSON, Arrow, SQLite 等；
        - **远程存储：** 原生支持 **AWS S3、Google Cloud Storage (GCS)、Azure Blob Storage** 以及其他 S3 兼容的存储。它只会按需读取所需的数据片段，而不是下载整个文件，非常适合云端数据分析；
            
6. **扩展性 (Extensibility)：**
    - DuckDB 拥有一个扩展系统，允许用户安装和加载额外的功能，例如对新的文件格式、新的函数或新的外部数据源的支持；
    
7. **开源 (Open Source)：**
    - DuckDB 是一个开源项目，拥有活跃的社区支持；
        

### 1.1.3 典型应用场景：

- **本地数据分析：** 作为 Python (Pandas) 或 R 语言数据分析的替代或补充，处理本地 CSV, Parquet 等文件；
- **交互式数据探索：** 快速对数据进行探索性分析，无需启动大型数据仓库或 Spark 集群；
- **数据管道中的轻量级 ETL：** 在数据管道的边缘或中间阶段进行数据转换和清理；
- **数据可视化工具的后端：** 作为桌面或 Web 应用中数据可视化组件的本地数据引擎；
- **云数据分析：** 直接查询 S3、GCS 等云存储上的大数据文件，进行快速 ad-hoc 查询；
- **嵌入式分析：** 在需要分析功能的应用程序中嵌入数据库；

## 1.2 技术解释

### 1.2.1 列式存储 (Columnar Storage)

列式存储（**Columnar Storage**）是一种与传统行式存储（**Row-based Storage**）相对的数据存储方式，广泛用于数据仓库、OLAP系统和分析型数据库中（如 Apache Parquet, Apache ORC, ClickHouse, ColumnStore 等）。列式存储的设计目标是**最大化读性能与压缩效率**，它在设计上做出如下权衡：

- **牺牲写入性能**（写一行要拆成多列分开写）；
- **提升读性能**（查询特定列时更快）；
- **提高压缩比与计算效率**；
    
因此，列式存储成为现代分析型数据库、数据仓库等系统的首选结构。相比之下，行式存储更适用于传统关系型数据库与事务处理系统。

#### 1. 什么是列式存储

在**列式存储**中，数据库将每一列的数据**独立存储**在物理磁盘或内存中。假设有如下表格（行式存储下的数据）：

|ID|Name|Age|Salary|
|---|---|---|---|
|1|Alice|30|50000|
|2|Bob|35|60000|
|3|Charlie|40|70000|
**行式存储**会按顺序存储整个行的数据块（如：1, Alice, 30, 50000 | 2, Bob, 35, 60000）。

**列式存储**则分别存储列（如下）：
- ID: `1, 2, 3`；
- Name: `Alice, Bob, Charlie`；
- Age: `30, 35, 40`；
- Salary: `50000, 60000, 70000`；

#### 设计原因与优势

**1. 优化查询性能（尤其是分析型查询）**

- 在数据分析中，常常只需读取某几列数据（例如：`SELECT Age, Salary FROM employees`）；
- 列式存储可以只扫描所需的列，**避免读取无关列的数据**，显著减少 I/O 和内存使用；
    

**2. 更高的压缩率**

- 相同类型的数据连续存储（例如：Salary列全是数字），更适合**压缩算法**（如RLE、字典编码、位图编码等）；
- 相较于行式存储的数据杂糅格式，列式压缩后体积小，读取速度快；
    
**3. 更适合向量化计算**

- 列式数据格式天然适合**SIMD指令集**进行批量处理（如向量加减乘除），在现代CPU上效率更高。

**4. 易于并行处理**

- 各列数据可独立读取与处理，**并行化效率高**，在大规模并发分析任务中表现优越；

### 1.2.2 Parquet 格式

Apache Parquet 是一种**列式存储格式**，专为高效存储和处理**大规模数据分析任务**而设计。它被广泛用于大数据生态系统（如 Hadoop, Spark, Presto, Hive 等）中。

#### Parquet 的内部结构

Parquet 的文件结构是层级化的，**文件 → Row Group → Column Chunk → Page**，如下所示：

```Markdown
+------------------------+
|     Parquet File       |
+------------------------+
| File Header            |
| Row Group(s)           |  ← 一或多个
|   Column Chunk(s)      |    ← 每列独立存储
|     Page(s)            |      ← Data/Dictionary/Index
| File Footer (Metadata) |
+------------------------+
```

**1. File Header**

- 标志魔数（magic number）：`PAR1`，用于标识文件是 Parquet 格式。

**2. Row Group（行组）**

- 一个 row group 中保存一定数量的**完整行**，但每列数据是**分开存储**的；
- 每个 row group 可独立读取，**并发读取非常高效**；

**3. Column Chunk（列块）**

- 每个列数据在 row group 中为一个 column chunk，数据类型一致；
- 每个 column chunk 中可进一步压缩、编码；

**4. Page（页）**

- Column Chunk 被划分为多个 page，分为三种类型：
    - **Data Page**：实际数据存储页（可包含压缩与编码）；
    - **Dictionary Page**：词典编码页（用于低基数字段）；
    - **Index Page（可选）**：用于定位查找优化；

**5. File Footer（元数据）**

- 描述所有 row group, column chunk 的元信息（offset、schema、统计信息等）；
- 支持 predicate pushdown（谓词下推）与 schema evolution（模式演进）;

#### 设计原理与优化技术

**1. 列式存储结构**

- 允许只读取所需的列，显著减少 I/O，适合 SELECT 查询分析；

**2. 压缩与编码优化**

- 支持多种编码（如 RLE, Bit Packing, Delta 等）与压缩（如 Snappy, Gzip, ZSTD）； 
    - 同类型数据连续，压缩率高；
    - 编码减少重复（如日期、性别、状态字段）；

**3. 谓词下推（Predicate Pushdown）**

- 通过读取 footer 中的 min/max 等统计信息，**跳过不相关的数据块**，加速查询； 

**4. Schema 演进（Schema Evolution）**

- 支持字段的添加/删除； 
- 读写解耦，允许未来扩展字段但兼容旧文件；

**5. 向量化计算（Vectorized Execution）**

- 结构支持批量读取列数据，优化 Spark, Presto 的向量化处理；

#### 选择合适的格式

**Parquet 文件** 和 **DuckDB 数据库表** 都可以用来高效存储列式数据，支持分析型查询，但它们适用的场景有重要区别。从以下几个角度来系统对比它们，**什么时候用 Parquet 文件，什么时候用 DuckDB 表**更合适。

**1. 核心差异概览**

| 对比维度 | Parquet 文件              | DuckDB 表（内置或持久化） |
| ---- | ----------------------- | ---------------- |
| 存储形式 | 纯文件，列式存储                | 嵌入式数据库，支持表结构     |
| 写入操作 | 较慢，不适合频繁写               | 支持写入、更新、事务       |
| 查询能力 | 需依赖引擎加载（如 Pandas、Spark） | SQL 原生、内嵌、即开即用   |
| 查询性能 | 优秀（尤其大文件 + 过滤）          | 极快（向量化 + 索引）     |
| 事务支持 | 不支持                     | 支持事务、索引、JOIN     |
| 易移植性 | 极高，跨工具标准格式              | 好，但依赖 DuckDB 引擎  |
| 文件大小 | 更适合 TB 级别以上             | 适合中小数据（MB~GB）    |
**2. Parquet 推荐使用场景**

- **数据共享与跨系统传输**
	- Parquet 是标准格式，兼容 Spark, Hive, Pandas, Snowflake, Presto, Athena 等；
	- 用于“数据湖”场景，特别适合“写一次、读多次”；
		- 例：将 ETL 处理好的数据导出为 Parquet，供 BI 工具或其他系统分析；
- **静态、大规模分析数据存储**
	- TB 级别数据（日志、监控、行为数据）存储成本低，读取快；
	- 无需频繁更新，只需要高效读取；
		例：用户行为日志、交易记录的归档数据；
- **长期归档**
	- Parquet 文件可压缩、可版本控制，适合持久存储历史快照数据；

**3. 使用 DuckDB 数据库表的场景** 

- **交互式、本地分析场景**
	- 数据量不大（一般小于100GB），但需要频繁做 SQL 查询分析、聚合、连接等；
	- 查询语法更丰富，且速度极快（向量化引擎）；
		- 例：本地 CSV 转换、临时分析、Jupyter Notebook 数据实验；
- **数据需要写入、更新或暂存**
	- 支持 INSERT、UPDATE、DELETE；
	- 可以直接缓存中间结果，适合数据探索或流水线任务中的中间状态。
		- 例：数据清洗或多步处理流程中的中间阶段。
- **Parquet 读取太慢的情况下（小数据）**
	- DuckDB 加载 Parquet 虽快，但对小数据（几十万行以内），用内存表更直接；

**4. 混合用法（推荐模式）**

实际上，**最佳实践是混合使用** Parquet 和 DuckDB。

| 步骤   | 用途        | 技术建议                    |
| ---- | --------- | ----------------------- |
| 数据准备 | 存储原始或历史数据 | 用 Parquet 存档            |
| 加载分析 | 临时读入、联表处理 | 用 DuckDB SQL 操作 Parquet |
| 中间结果 | 缓存或调试数据   | 用 DuckDB 内存表或持久表        |
| 输出共享 | 导出结果数据    | 输出为 Parquet 或 CSV       |

#### 转换 csv 文件到 parquet

```bash
duckdb -c "COPY (SELECT * FROM read_csv_auto('./2024-05.csv')) TO './2024-05.parquet' (FORMAT 'parquet');"
```

### 1.2.3 Parquet 文件存储方式

对于非敏感数据，我们可以把`parquet`文件上传到`github`上保存。对于敏感数据有以下几种处理方式：
1. 本地保存，然后使用`duckdb`进行分析；
2. 保存在`Google Drive`上，然后使用`colab`服务，利用`python + duckdb`进行处理；
3. 保存在`S3、GCS`等云服务器上，然后进行处理；

#### GCS (Google Cloud Storage) 保存文件

